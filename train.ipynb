{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Visualize Single Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_file_name = \"./blues.00000.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y,sr = librosa.load(random_file_name,sr=50000) ##sr=44100\n",
    "plt.figure(figsize=(14,5))\n",
    "librosa.display.waveshow(y,sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Playing Sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(data=y,rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing Visualization on chunks of Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = \"./blues.00000.wav\"\n",
    "y,sr = librosa.load(random_file_name,sr=None) #sr=None means original sampling rate\n",
    "\n",
    "#define duration of chunk and overlap\n",
    "chunk_duration = 4\n",
    "overlap_duration = 2\n",
    "\n",
    "#Convert duartion to sample\n",
    "chunk_samples = chunk_duration * sr\n",
    "overlap_samples = overlap_duration * sr\n",
    "\n",
    "\n",
    "#Calculate the number of chunks\n",
    "num_chunks = int(np.ceil((len(y)-chunk_samples)/(chunk_samples-overlap_samples)))+1\n",
    "\n",
    "#Iterate over each chunk\n",
    "\n",
    "for i in range (num_chunks):\n",
    "    #Calculate start and end indices of each chunk\n",
    "    start = i*(chunk_samples-overlap_samples)\n",
    "    end = start + chunk_samples\n",
    "    #Extract the chunk Audio\n",
    "    chunk = y[start:end]\n",
    "    plt.Figure(figsize=(4,2))\n",
    "    librosa.display.waveshow(chunk,sr=sr)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melspectogram Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting  Melspectogram of entire Audio\n",
    "def plot_melspectogram(y,sr):\n",
    "    #Compute Spectogram\n",
    "    spectogram = librosa.feature.melspectrogram(y=y,sr=sr)\n",
    "    #Convert to decibles (log scale)\n",
    "    spectogram_db = librosa.power_to_db(spectogram, ref=np.max)\n",
    "    #Visualize spectogram\n",
    "    plt.figure(figsize=(10,4))\n",
    "    librosa.display.specshow(spectogram_db,sr=sr,x_axis='time',y_axis='mel')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Melspectogram')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_file_name = \"./blues.00000.wav\"\n",
    "y,sr = librosa.load(random_file_name,sr=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For entire Audio\n",
    "plot_melspectogram(y,sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_melspectogram_chunks(y,sr):\n",
    "    audio_path = \"./blues.00000.wav\"\n",
    "y,sr = librosa.load(random_file_name,sr=None) #sr=None means original sampling rate\n",
    "\n",
    "#define duration of chunk and overlap\n",
    "chunk_duration = 4\n",
    "overlap_duration = 2\n",
    "\n",
    "#Convert duartion to sample\n",
    "chunk_samples = chunk_duration * sr\n",
    "overlap_samples = overlap_duration * sr\n",
    "\n",
    "\n",
    "#Calculate the number of chunks\n",
    "num_chunks = int(np.ceil((len(y)-chunk_samples)/(chunk_samples-overlap_samples)))+1\n",
    "\n",
    "#Iterate over each chunk\n",
    "\n",
    "for i in range (num_chunks):\n",
    "    #Calculate start and end indices of each chunk\n",
    "    start = i*(chunk_samples-overlap_samples)\n",
    "    end = start + chunk_samples\n",
    "    #Extract the chunk Audio\n",
    "    chunk = y[start:end]\n",
    "    #Melspectogram of each chunk\n",
    "    melspectogram = librosa.feature.melspectrogram(y=chunk,sr=sr)\n",
    "    spectogram_db = librosa.power_to_db(melspectogram, ref=np.max)\n",
    "    #visualize melspectogram\n",
    "    plt.figure(figsize=(10,4))\n",
    "    librosa.display.specshow(spectogram_db,sr=sr,x_axis='time',y_axis='mel')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Melspectogram')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_file_name=\"./blues.00000.wav\"\n",
    "y,sr = librosa.load(random_file_name,sr=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_melspectogram_chunks(y,sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=32,kernel_size=3,padding='same',activation='relu',input_shape=X_train[0].shape))\n",
    "model.add(Conv2D(filters=32,kernel_size=3,activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=64,kernel_size=3,padding='same',activation='relu'))\n",
    "model.add(Conv2D(filters=64,kernel_size=3,activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=128,kernel_size=3,padding='same',activation='relu'))\n",
    "model.add(Conv2D(filters=128,kernel_size=3,activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=256,kernel_size=3,padding='same',activation='relu'))\n",
    "model.add(Conv2D(filters=256,kernel_size=3,activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=512,kernel_size=3,padding='same',activation='relu'))\n",
    "model.add(Conv2D(filters=512,kernel_size=3,activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=1200,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=len(classes),activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history = model.fit(X_train,Y_train,epochs=30,batch_size=32,validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Trained_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history.history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
